{
    "name": "root",
    "gauges": {
        "FetchGamePhysics.Policy.Entropy.mean": {
            "value": 1.3112143278121948,
            "min": 1.3112114667892456,
            "max": 1.4189382791519165,
            "count": 500
        },
        "FetchGamePhysics.Policy.Entropy.sum": {
            "value": 13626.1396484375,
            "min": 12381.802734375,
            "max": 15496.2255859375,
            "count": 500
        },
        "FetchGamePhysics.Environment.LessonNumber.obstacle_scale_vs_ramp.mean": {
            "value": 6.0,
            "min": 0.0,
            "max": 6.0,
            "count": 500
        },
        "FetchGamePhysics.Environment.LessonNumber.obstacle_scale_vs_ramp.sum": {
            "value": 6.0,
            "min": 0.0,
            "max": 6.0,
            "count": 500
        },
        "FetchGamePhysics.Environment.LessonNumber.ball_fetched_threshold.mean": {
            "value": 6.0,
            "min": 0.0,
            "max": 6.0,
            "count": 500
        },
        "FetchGamePhysics.Environment.LessonNumber.ball_fetched_threshold.sum": {
            "value": 6.0,
            "min": 0.0,
            "max": 6.0,
            "count": 500
        },
        "FetchGamePhysics.Environment.EpisodeLength.mean": {
            "value": 311.34375,
            "min": 21.424242424242426,
            "max": 999.0,
            "count": 500
        },
        "FetchGamePhysics.Environment.EpisodeLength.sum": {
            "value": 9963.0,
            "min": 707.0,
            "max": 15392.0,
            "count": 500
        },
        "FetchGamePhysics.Step.mean": {
            "value": 4999979.0,
            "min": 9956.0,
            "max": 4999979.0,
            "count": 500
        },
        "FetchGamePhysics.Step.sum": {
            "value": 4999979.0,
            "min": 9956.0,
            "max": 4999979.0,
            "count": 500
        },
        "FetchGamePhysics.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.015802400186657906,
            "min": -0.10716094821691513,
            "max": 0.45612233877182007,
            "count": 500
        },
        "FetchGamePhysics.Policy.ExtrinsicValueEstimate.sum": {
            "value": 1.5170304775238037,
            "min": -8.5728759765625,
            "max": 66.13774108886719,
            "count": 500
        },
        "FetchGamePhysics.Environment.CumulativeReward.mean": {
            "value": 0.2047708525788039,
            "min": -2.282125244382769,
            "max": 0.8038127079154506,
            "count": 500
        },
        "FetchGamePhysics.Environment.CumulativeReward.sum": {
            "value": 6.552667282521725,
            "min": -36.5140039101243,
            "max": 98.76330311596394,
            "count": 500
        },
        "FetchGamePhysics.Policy.ExtrinsicReward.mean": {
            "value": 0.2047708525788039,
            "min": -2.282125244382769,
            "max": 0.8038127079154506,
            "count": 500
        },
        "FetchGamePhysics.Policy.ExtrinsicReward.sum": {
            "value": 6.552667282521725,
            "min": -36.5140039101243,
            "max": 98.76330311596394,
            "count": 500
        },
        "FetchGamePhysics.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 500
        },
        "FetchGamePhysics.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 500
        },
        "FetchGamePhysics.Losses.PolicyLoss.mean": {
            "value": 0.017979119873295226,
            "min": 0.010984572178373734,
            "max": 0.02411853753340741,
            "count": 243
        },
        "FetchGamePhysics.Losses.PolicyLoss.sum": {
            "value": 0.017979119873295226,
            "min": 0.010984572178373734,
            "max": 0.02411853753340741,
            "count": 243
        },
        "FetchGamePhysics.Losses.ValueLoss.mean": {
            "value": 0.015552312849710386,
            "min": 0.0013613969960715622,
            "max": 0.03731379856665929,
            "count": 243
        },
        "FetchGamePhysics.Losses.ValueLoss.sum": {
            "value": 0.015552312849710386,
            "min": 0.0013613969960715622,
            "max": 0.03731379856665929,
            "count": 243
        },
        "FetchGamePhysics.Policy.LearningRate.mean": {
            "value": 4.187798604400158e-07,
            "min": 4.187798604400158e-07,
            "max": 0.00029876904041032,
            "count": 243
        },
        "FetchGamePhysics.Policy.LearningRate.sum": {
            "value": 4.187798604400158e-07,
            "min": 4.187798604400158e-07,
            "max": 0.00029876904041032,
            "count": 243
        },
        "FetchGamePhysics.Policy.Epsilon.mean": {
            "value": 0.10013956000000004,
            "min": 0.10013956000000004,
            "max": 0.19958968,
            "count": 243
        },
        "FetchGamePhysics.Policy.Epsilon.sum": {
            "value": 0.10013956000000004,
            "min": 0.10013956000000004,
            "max": 0.19958968,
            "count": 243
        },
        "FetchGamePhysics.Policy.Beta.mean": {
            "value": 1.696404400000026e-05,
            "min": 1.696404400000026e-05,
            "max": 0.004979525032,
            "count": 243
        },
        "FetchGamePhysics.Policy.Beta.sum": {
            "value": 1.696404400000026e-05,
            "min": 1.696404400000026e-05,
            "max": 0.004979525032,
            "count": 243
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1653344914",
        "python_version": "3.9.12 (tags/v3.9.12:b28265d, Mar 23 2022, 23:52:46) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\kryst\\AppData\\Roaming\\Python\\Python39\\Scripts\\mlagents-learn FetchGamePhysicsTraining\\trainer_config_obstacle.yaml --env FetchGamePhysics\\FetchArenaProject\\Builds\\ObstacleTest\\rig_room --num-envs 16 --torch-device cuda --results-dir FetchGamePhysics\\FetchArenaProject\\Assets\\Results --run-id ObstacleTest01 --no-graphic --force",
        "mlagents_version": "0.29.0",
        "mlagents_envs_version": "0.29.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1653355342"
    },
    "total": 10427.9110716,
    "count": 1,
    "self": 1.1076909999992495,
    "children": {
        "run_training.setup": {
            "total": 1.2651331,
            "count": 1,
            "self": 1.2651331
        },
        "TrainerController.start_learning": {
            "total": 10425.5382475,
            "count": 1,
            "self": 187.8484622998676,
            "children": {
                "TrainerController._reset_env": {
                    "total": 10.9868965,
                    "count": 1,
                    "self": 10.9868965
                },
                "TrainerController.advance": {
                    "total": 10226.659487800132,
                    "count": 361263,
                    "self": 11.679732000196964,
                    "children": {
                        "env_step": {
                            "total": 9197.179162500115,
                            "count": 361263,
                            "self": 1202.7916463985666,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 7973.89636950158,
                                    "count": 5013053,
                                    "self": 254.56395670148595,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 7719.332412800094,
                                            "count": 5000980,
                                            "self": 2819.131170399477,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 4900.201242400617,
                                                    "count": 5000980,
                                                    "self": 4900.201242400617
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 20.491146599968665,
                                    "count": 361263,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 166510.45575008058,
                                            "count": 5013051,
                                            "is_parallel": true,
                                            "self": 149176.02471137798,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.007841399999998444,
                                                    "count": 16,
                                                    "is_parallel": true,
                                                    "self": 0.0028358999999920087,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.005005500000006435,
                                                            "count": 64,
                                                            "is_parallel": true,
                                                            "self": 0.005005500000006435
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 17334.42319730261,
                                                    "count": 5013051,
                                                    "is_parallel": true,
                                                    "self": 404.291242201627,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 349.5549868003744,
                                                            "count": 5013051,
                                                            "is_parallel": true,
                                                            "self": 349.5549868003744
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 15437.6355772008,
                                                            "count": 5013051,
                                                            "is_parallel": true,
                                                            "self": 15437.6355772008
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 1142.9413910998098,
                                                            "count": 5013051,
                                                            "is_parallel": true,
                                                            "self": 493.0109705981738,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 649.930420501636,
                                                                    "count": 20052204,
                                                                    "is_parallel": true,
                                                                    "self": 649.930420501636
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 1017.8005932998201,
                            "count": 361263,
                            "self": 10.0724234997258,
                            "children": {
                                "process_trajectory": {
                                    "total": 291.93802390010023,
                                    "count": 361263,
                                    "self": 291.5612246000999,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.3767993000003571,
                                            "count": 10,
                                            "self": 0.3767993000003571
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 715.7901458999941,
                                    "count": 243,
                                    "self": 560.8117513000248,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 154.9783945999693,
                                            "count": 7290,
                                            "self": 154.9783945999693
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 8.000006346264854e-07,
                    "count": 1,
                    "self": 8.000006346264854e-07
                },
                "TrainerController._save_models": {
                    "total": 0.04340009999941685,
                    "count": 1,
                    "self": 0.010833199998160126,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.03256690000125673,
                            "count": 1,
                            "self": 0.03256690000125673
                        }
                    }
                }
            }
        }
    }
}
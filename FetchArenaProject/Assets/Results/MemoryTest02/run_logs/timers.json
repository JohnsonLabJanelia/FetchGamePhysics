{
    "name": "root",
    "gauges": {
        "FetchGamePhysicsMemory.Policy.Entropy.mean": {
            "value": 1.403358817100525,
            "min": 1.403358817100525,
            "max": 1.4386571645736694,
            "count": 55
        },
        "FetchGamePhysicsMemory.Policy.Entropy.sum": {
            "value": 13991.4873046875,
            "min": 13308.654296875,
            "max": 15406.83203125,
            "count": 55
        },
        "FetchGamePhysicsMemory.Environment.LessonNumber.ball_max_angular_velocity.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 55
        },
        "FetchGamePhysicsMemory.Environment.LessonNumber.ball_max_angular_velocity.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 55
        },
        "FetchGamePhysicsMemory.Environment.LessonNumber.ball_fetched_threshold.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 55
        },
        "FetchGamePhysicsMemory.Environment.LessonNumber.ball_fetched_threshold.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 55
        },
        "FetchGamePhysicsMemory.Environment.EpisodeLength.mean": {
            "value": 10.310305775764439,
            "min": 10.310305775764439,
            "max": 460.2,
            "count": 55
        },
        "FetchGamePhysicsMemory.Environment.EpisodeLength.sum": {
            "value": 9104.0,
            "min": 1062.0,
            "max": 16161.0,
            "count": 55
        },
        "FetchGamePhysicsMemory.Step.mean": {
            "value": 549988.0,
            "min": 9927.0,
            "max": 549988.0,
            "count": 55
        },
        "FetchGamePhysicsMemory.Step.sum": {
            "value": 549988.0,
            "min": 9927.0,
            "max": 549988.0,
            "count": 55
        },
        "FetchGamePhysicsMemory.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.8649724125862122,
            "min": 0.04072032868862152,
            "max": 0.8772656321525574,
            "count": 55
        },
        "FetchGamePhysicsMemory.Policy.ExtrinsicValueEstimate.sum": {
            "value": 763.7706298828125,
            "min": 3.9498720169067383,
            "max": 763.7706298828125,
            "count": 55
        },
        "FetchGamePhysicsMemory.Environment.CumulativeReward.mean": {
            "value": 0.902926661825126,
            "min": -0.2331480046113332,
            "max": 0.9178694081471263,
            "count": 55
        },
        "FetchGamePhysicsMemory.Environment.CumulativeReward.sum": {
            "value": 797.2842423915863,
            "min": -6.994440138339996,
            "max": 797.2842423915863,
            "count": 55
        },
        "FetchGamePhysicsMemory.Policy.ExtrinsicReward.mean": {
            "value": 0.902926661825126,
            "min": -0.2331480046113332,
            "max": 0.9178694081471263,
            "count": 55
        },
        "FetchGamePhysicsMemory.Policy.ExtrinsicReward.sum": {
            "value": 797.2842423915863,
            "min": -6.994440138339996,
            "max": 797.2842423915863,
            "count": 55
        },
        "FetchGamePhysicsMemory.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 55
        },
        "FetchGamePhysicsMemory.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 55
        },
        "FetchGamePhysicsMemory.Losses.PolicyLoss.mean": {
            "value": 0.03288838379861166,
            "min": 0.024777251346192013,
            "max": 0.04219054619391803,
            "count": 28
        },
        "FetchGamePhysicsMemory.Losses.PolicyLoss.sum": {
            "value": 0.03288838379861166,
            "min": 0.024777251346192013,
            "max": 0.04219054619391803,
            "count": 28
        },
        "FetchGamePhysicsMemory.Losses.ValueLoss.mean": {
            "value": 0.002106165148628255,
            "min": 0.0019208574706378082,
            "max": 0.04453960247337818,
            "count": 28
        },
        "FetchGamePhysicsMemory.Losses.ValueLoss.sum": {
            "value": 0.002106165148628255,
            "min": 0.0019208574706378082,
            "max": 0.04453960247337818,
            "count": 28
        },
        "FetchGamePhysicsMemory.Policy.LearningRate.mean": {
            "value": 0.00028362093545969,
            "min": 0.00028362093545969,
            "max": 0.0002993870102043301,
            "count": 28
        },
        "FetchGamePhysicsMemory.Policy.LearningRate.sum": {
            "value": 0.00028362093545969,
            "min": 0.00028362093545969,
            "max": 0.0002993870102043301,
            "count": 28
        },
        "FetchGamePhysicsMemory.Policy.Epsilon.mean": {
            "value": 0.19454030999999997,
            "min": 0.19454030999999997,
            "max": 0.19979567000000006,
            "count": 28
        },
        "FetchGamePhysicsMemory.Policy.Epsilon.sum": {
            "value": 0.19454030999999997,
            "min": 0.19454030999999997,
            "max": 0.19979567000000006,
            "count": 28
        },
        "FetchGamePhysicsMemory.Policy.Beta.mean": {
            "value": 0.004727561468999999,
            "min": 0.004727561468999999,
            "max": 0.004989803932999999,
            "count": 28
        },
        "FetchGamePhysicsMemory.Policy.Beta.sum": {
            "value": 0.004727561468999999,
            "min": 0.004727561468999999,
            "max": 0.004989803932999999,
            "count": 28
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1653099916",
        "python_version": "3.9.12 (tags/v3.9.12:b28265d, Mar 23 2022, 23:52:46) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\kryst\\AppData\\Roaming\\Python\\Python39\\Scripts\\mlagents-learn Builds\\MemoryTest\\trainer_config.yaml --env Builds\\MemoryTest --run-id MemoryTest02 --force --results-dir Assets\\Results",
        "mlagents_version": "0.29.0",
        "mlagents_envs_version": "0.29.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1653101800"
    },
    "total": 1883.958689,
    "count": 1,
    "self": 4.020262399999865,
    "children": {
        "run_training.setup": {
            "total": 1.2516954,
            "count": 1,
            "self": 1.2516954
        },
        "TrainerController.start_learning": {
            "total": 1878.6867312000002,
            "count": 1,
            "self": 2.6077662999937274,
            "children": {
                "TrainerController._reset_env": {
                    "total": 27.0299219,
                    "count": 1,
                    "self": 27.0299219
                },
                "TrainerController.advance": {
                    "total": 1848.8487760000066,
                    "count": 40352,
                    "self": 1.4174703999940448,
                    "children": {
                        "env_step": {
                            "total": 1511.010745200003,
                            "count": 40352,
                            "self": 151.934325700028,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1356.7758700999705,
                                    "count": 571566,
                                    "self": 37.597371799980465,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1319.17849829999,
                                            "count": 555842,
                                            "self": 585.7374803999896,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 733.4410179000004,
                                                    "count": 555842,
                                                    "self": 733.4410179000004
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 2.3005494000043782,
                                    "count": 40351,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 29926.030902200375,
                                            "count": 571553,
                                            "is_parallel": true,
                                            "self": 27944.202597300347,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.005635499999998572,
                                                    "count": 16,
                                                    "is_parallel": true,
                                                    "self": 0.0020254999999993473,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.003609999999999225,
                                                            "count": 64,
                                                            "is_parallel": true,
                                                            "self": 0.003609999999999225
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1981.8226694000286,
                                                    "count": 571553,
                                                    "is_parallel": true,
                                                    "self": 45.67236050007091,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 36.923745599948134,
                                                            "count": 571553,
                                                            "is_parallel": true,
                                                            "self": 36.923745599948134
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1772.0437114999309,
                                                            "count": 571553,
                                                            "is_parallel": true,
                                                            "self": 1772.0437114999309
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 127.1828518000786,
                                                            "count": 571553,
                                                            "is_parallel": true,
                                                            "self": 52.57903880018934,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 74.60381299988926,
                                                                    "count": 2286212,
                                                                    "is_parallel": true,
                                                                    "self": 74.60381299988926
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 336.4205604000097,
                            "count": 40351,
                            "self": 1.1026945999825557,
                            "children": {
                                "process_trajectory": {
                                    "total": 231.3514424000267,
                                    "count": 40351,
                                    "self": 231.3514424000267
                                },
                                "_update_policy": {
                                    "total": 103.96642340000045,
                                    "count": 28,
                                    "self": 23.32091639999993,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 80.64550700000052,
                                            "count": 840,
                                            "self": 80.64550700000052
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.4999998256826075e-06,
                    "count": 1,
                    "self": 1.4999998256826075e-06
                },
                "TrainerController._save_models": {
                    "total": 0.20026549999988674,
                    "count": 1,
                    "self": 0.011236599999847385,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.18902890000003936,
                            "count": 1,
                            "self": 0.18902890000003936
                        }
                    }
                }
            }
        }
    }
}